--- Page 1 ---
LLM-CBT: LLM-Driven Closed-Loop Behavior Tree Planning for
Heterogeneous UAV-UGV Swarm Collaboration
Yuanyuan Tian1, Weilong Song2,5, Jinna Fu3, Zhenhui Li1,3∗, Chenyu Fang1,
Linbo Wang1, Wanyang Hu1 and Yabo Liu4
Abstract— The heterogeneous cluster system holds significant
application potential in scenarios such as collaborative logistics,
disaster response operations, and precision agriculture, but
achieving effective task planning for its subsystems remains
a challenging issue due to specialized robotic hardware and
distinct action spaces. To this end, an innovative framework
called LLM-driven Closed-Loop Behavior Tree (LLM-CBT)
is proposed. LLMs and behavior trees (BTs) are integrated
for task planning in heterogeneous unmanned clusters, in-
cluding Unmanned Aerial Vehicles (UAVs) and Unmanned
Ground Vehicles (UGVs). Particularly, a novel mechanism,
Generation-Refinement-Execution-Feedback (GREF), is intro-
duced, in which an initial behavior tree is generated by
LLM and iteratively refined. The refined behavior tree is then
executed, and adjustments are made based on the execution
results, forming a closed-loop process that ultimately achieves
the task objectives. In this way, the executability of BTs is
improved, and the robustness of task execution in dynamic
environments is enhanced. Experiments were conducted across
three scenarios with varying task complexity. The results show
that the GREF closed-loop mechanism is essential for the
effective operation of heterogeneous unmanned clusters.
I. INTRODUCTION
Unmanned clusters are playing an increasingly vital role
in urban security [1], emergency response [2], and intel-
ligent transportation [3]. However, as application require-
ments grow and tasks become more complex, homogeneous
unmanned clusters often struggle with task execution. In
contrast, more complex and diverse tasks can be addressed
through efficient collaboration by heterogeneous cluster sys-
tems consisting of multiple unmanned aerial vehicles (UAVs)
and unmanned ground vehicles (UGVs). A key challenge in
task planning for such systems is effectively utilizing each
agent’s unique capabilities to ensure seamless cooperation.
Meanwhile, Large Language models (LLMs) have been
widely used in multi-robot task planning [4][5][6], leveraging
their capabilities in understanding natural language, logical
reasoning, and generalization. However, the natural language
instructions generated by LLMs are usually high-level and
abstract, while the action instructions executed by robots are
low-level and concrete. To bridge this gap, behavior trees
(BTs) abstract low-level control operations into structured
*corresponding author: Zhenhui Li. lizhenhui@zju.edu.cn
1 College of Control Science and Engineering, Zhejiang University
2 China North Artificial Intelligence & Innovation Research Institute
3 Ocean College, Zhejiang University, Zhoushan, 316021, China
4 College of Computer Science and Technology, Zhejiang University
5 Collective Intelligence & Collaboration Laboratory
This work is supported by the National Natural Science Foundation of
China (grant No.: U2441244).
action and condition nodes, making them more interpretable
and manageable for LLMs. Current methods for automating
BT generation [7][8][9] still greatly rely on manual design
for basic structures or available subtrees, which is time-
consuming and requires domain expertise.
To this end, LLM-CBT, as shown in Fig. 1, is proposed
in this paper as an LLM-based BT generation framework
to leverage the strengths of both for task planning in
heterogeneous unmanned clusters. Based on the reasoning
capabilities and prior knowledge of LLMs, behavior trees
can be quickly generated and dynamically adjusted to adapt
to the environment without the need for manual coding.
Specifically, a Generation-Refinement-Execution-Feedback
(GREF) framework is developed to enhance BT generation
performance and improve the task success rate. Based on
this, a novel closed-loop mechanism is presented, ensuring
the efficiency and feasibility of task planning. The main
contributions of this study are summarized as follows:
• A novel framework is proposed that utilizes LLMs to
generate executable BTs for task planning in hetero-
geneous unmanned clusters, facilitating efficient task
coordination among unmanned agents with diverse ca-
pabilities, such as UAVs and UGVs.
• A closed-loop task planning and execution mechanism
called GREF is presented to improve the executability
of BTs and significantly increase the success rate of
tasks.
• Experiments with multiple scenarios and varying task
complexity were designed to validate the proposed
method, demonstrating its advantages in key metrics
such as task success rate, execution efficiency, and
executability.
II. RELATED WORK
A. Behavior Trees in Robotics
Behavior Trees have been extensively implemented in
game AI and robotic behavior modeling owing to the ad-
vantages of reactivity, modularity, hierarchical structure, and
real-time feedback [10]. BT expansion [11] was the first to
leverage the state-space of BTs, providing a novel approach
for intelligent robot behavior planning. Furthermore, rein-
forcement learning (RL) has been applied to autonomously
acquire BTs for task-level control [12]. To further enhance
the execution efficiency and adaptability of BTs, various
improvements have been proposed. For example, Conditional
Behavior Trees (CBTs) [13] monitored the execution of
2025 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2025)
October 19-25, 2025. Hangzhou, China
979-8-3315-4393-8/25/$31.00 ©2025 IEEE
3581
2025 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) | 979-8-3315-4393-8/25/$31.00 ©2025 IEEE | DOI: 10.1109/IROS60139.2025.11246793
Authorized licensed use limited to: Consortium - Saudi Arabia SDL. Downloaded on February 16,2026 at 10:06:57 UTC from IEEE Xplore.  Restrictions apply. 


--- Page 2 ---
Fig. 1.
System Overview: The four key stages of LLM-CBT are as follows: (a) Generation: a few-shot prompt, including task instructions I, components
of unmanned clusters, a behavior library, examples and requirements, is fed to LLM to generate an initial behavior tree in XML format; (b) Refinement: a
refinement prompt, along with initial behavior tree, is given to the LLM to self-refine the tree’s structure, parameters and logic; (c) Execution: the refined
behavior tree is executed in a simulation environment; (d) Feedback: if a failure occurs, feedback from both the behavior tree and human is provided to
the LLM for further adjustment.
individual actions by separately checking pre- and post-
conditions, significantly improving the executability of BTs.
Additionally, BTs generated by imitation learning [14] can
facilitate more effective adaptation to the environment. Belief
Behavior Trees (BBTs) [15], by introducing belief states,
allow task planning with non-deterministic outcomes for
actions. An event-driven BT framework was proposed by
micROS.BT [16] to support swarm-robot coordination.
B. LLM-based methods for Multi-robot task Planning
Research on multi-robot task planning utilizing LLMs
is primarily categorized into two frameworks: centralized
and decentralized [17]. In the domain of decentralized task
planning, Liu, Xinzhu, et al. [18] harnessed the advanced
reasoning capabilities of LLMs to propose an innovative
decentralized framework capable of generating efficient col-
laboration strategies for heterogeneous ad hoc teams. Addi-
tionally, the CoELA [4] framework was introduced with five
core modules: perception, memory, communication, plan-
ning, and execution, with a decentralized architecture to en-
hance robot information sharing. RoCo [5] integrated a multi-
agent dialogue mechanism with low-level path planning, thus
facilitating efficient collaboration within robot teams.
In the field of centralized architectures, a novel “robot re-
sume” mechanism was introduced by the EMOS framework
[19], which significantly enhanced the embodied reasoning
capabilities of robots, and offered a new approach for col-
laborative operations in heterogeneous multi-robot systems.
SMART-LLM [6], employing a centralized approach, con-
verted high-level task instructions into a multi-robot task
plan. The COHERENT framework [17] was proposed to
combine the benefits of centralized task decomposition with
distributed task execution.
C. LLM-Based Behavior Trees for Robotic Task Planning
BETR-XP-LLM [20] has been proposed to utilize LLM to
automatically expand BTs for robotic manipulation tasks. Be-
sides, a hierarchical framework was introduced by the LLM
as BT-Planner [21] that employs LLMs for BT generation,
encompassing high-level task decomposition, mid-level BT
generation, and low-level execution. A method for adaptive
task execution using LLMs and BTs was proposed by the
LLM-BT framework [22], focusing specifically on robotic
arm manipulation tasks. Wang, Jin et al. [23] used LLM
to generate a behavior tree framework based on a behavior
library and task instructions for decision making and task
execution.
While these approaches demonstrate the effectiveness of
LLM-based BT generation in robotic manipulation, their
application in unmanned swarm systems remains largely
unexplored. Existing methods to unmanned swarm task plan-
ning predominantly employ market mechanisms [24], swarm
intelligence [25], and game theory [26]. However, these
methods often necessitate complex system modeling and
demonstrate limited generalizability. In this work, we extend
the proven success of LLMs in robotic manipulation to the
domain of unmanned swarm coordination, thereby improving
generalizability and reducing system design complexity.
III. METHOD
As shown in Fig. 1, a GREF framework is proposed in
this paper. In the generation stage shown in Fig. 1(a), the
user instruction I, along with the behavior library and other
necessary information, is processed by the LLM-based plan-
ner at the beginning for task decomposition and allocation,
3582
Authorized licensed use limited to: Consortium - Saudi Arabia SDL. Downloaded on February 16,2026 at 10:06:57 UTC from IEEE Xplore.  Restrictions apply. 


--- Page 3 ---
generating an initial behavior tree. The complexity and length
of prompts in the generation phase can lead to omissions or
inconsistencies in the LLM’s output. Consequently, the initial
behavior tree may contain structural or parameter errors
that hinder its executability or exhibit suboptimal logic. To
address these issues, we introduce a refinement mechanism,
as depicted in Fig. 1(b), to further enhance the reliability
of the results. In this way, LLM can autonomously verify
the executability of the initial behavior tree and ensure the
optimality of its logical structure. Furthermore, as shown in
Fig. 1(c), the refined behavior tree is executed in a simulation
environment, where UAVs and UGVs executors execute
action and condition nodes to achieve the task objectives.
Finally, if failures occur, based on both execution and human
feedback, the LLM planner adjusts the behavior tree to
initiate the next iteration cycle, as illustrated in Fig. 1(d).
Based on the above GREF framework, the executability of
the behavior tree is ensured, thereby significantly enhancing
the task success rate. An example of a coordinated search-
and-rescue operation in Areas A and B, involving UAVs and
UGVs is used to illustrate these four processes in detail.
A. Behavior Tree Generation
As illustrated in Fig. 1(a), a few-shot prompt is given to the
LLM to decompose the task and assign the appropriate agents
to complete it. The input prompt is composed of a human-
provided task instruction I, the components of the unmanned
swarm system, a predefined behavior library, requirements of
task decomposition and allocation, as well as example cases.
Specifically, the unmanned swarm is composed of both
UAVs and UGVs, each having distinct action spaces and
capabilities, allowing specialized tasks to be performed. The
behavior library defines executable nodes for both, including
action and condition nodes. The action and condition nodes
defined in this paper are shown in Table I.
The initial behavior tree is generated by the LLM in
two key steps. The first step is task decomposition, where
complex natural language instructions are structured into a
behavior tree consisting of control nodes (including parallel,
sequential, and fallback) as well as action and condition
nodes. The second step is task allocation, where tasks are
assigned to the available agents by the LLM based on
their specific capabilities. Moreover, examples are provided
to guide the LLM in generating the initial behavior tree
through few-shot prompting. Three such examples are used,
each consisting of a human instruction and its corresponding
behavior tree.
Fig. 2 depicts the behavior tree generated in Stage A for
the given example. The task is divided into UAVs searching
areas A and B, and UGVs transporting emergency supplies.
However, the task is executed sequentially. This logical
structure results in low execution efficiency due to the lack
of parallelism. Therefore, a refinement module is introduced
to address issues like this.
B. Refinement of the Initial Behavior Tree
Several issues may be encountered in the initially gener-
ated behavior tree due to LLM hallucinations.
TABLE I
THE ACTION AND CONDITION NODES FOR UGVS AND UAVS
Node Type
Agent
Node List
Action Node
UAV
UAV MoveTo
UAV SearchPathGenerate
UAV SearchPathFollow
UAV TargetRecognize
UAV LocateTargetPosition
UAV BroadcastDispersal
UAV CollectData
UGV
UGV GlobalPlanning
UGV LocalPlanning
UGV Recovery
UGV EquipPayload
UGV UnloadPayload
UGV ReportInformation
Condition Node
UAV
UAV IsPositionReached
UAV IsTargetDetected
UAV IsSearchPathFollowingDone
UGV
UGV HasPayload
UGV IsDestinationReached
UGV IsNavigationTimeout
Fig. 2.
The initial behavior tree generated in Stage A, with the root node
as a Sequence. The subtasks are executed sequentially.
• Format errors: The behavior tree follows a strict
format specification, and any deviations from it will
prevent the tree from executing.
• Parameter errors: The input and output port parame-
ters of each action and condition node determine data
flow within the behavior tree. Incorrect parameters will
also prevent execution.
• Suboptimal logical structure: The initial task decom-
position and task allocation may result in a sequential
order of subtasks rather than parallel execution, leading
to inefficiency.
To address these issues, a refinement module is proposed
between the behavior tree generation and execution stages.
This module takes the initial behavior tree generated in Stage
A as input and leverages the LLM’s reasoning abilities to
assess its executability and logical optimality.
For example, through the refinement in Stage B, the initial
behavior tree shown in Fig. 2 is optimized into the refined
behavior tree depicted in Fig. 3. It can be observed that the
UAVs and the UGVs perform tasks in parallel, while each
unit also executes tasks in parallel with others.
C. Behavior Tree Execution
After the steps described above, the refined behavior tree
is executed by UAVs and UGVs to complete the user’s task
instructions in this stage. The execution logic is determined
3583
Authorized licensed use limited to: Consortium - Saudi Arabia SDL. Downloaded on February 16,2026 at 10:06:57 UTC from IEEE Xplore.  Restrictions apply. 


--- Page 4 ---
Fig. 3.
The refined behavior tree in Stage B, with the root node as a
Parallel. The subtasks are executed in parallel.
by the control nodes of the behavior tree (including parallel,
sequential, and fallback nodes), ensuring precise task execu-
tion.
The action and condition nodes of the behavior tree are
associated with sensor data processing and low-level control
algorithms. Some predefined functions are represented by ac-
tion nodes, as shown in Table I, such as positional navigation,
supply loading, and target identification. Condition nodes, on
the other hand, are responsible for evaluating whether the
current conditions are met. Only when the conditions are
satisfied will the execution flow proceed to the next node in
the behavior tree, thus guaranteeing the orderly progression
of the task execution process.
A behavior tree has three possible execution states, namely
“success”, “failure”, and “running”. The execution of the
behavior tree is determined to be successful only when the
root node of the behavior tree returns “success”. If the root
node of the behavior tree returns “failure”, the task execution
times out, or the target state is not reached, the behavior tree
will be adjusted in the feedback phase of the next stage.
D. Task Execution Feedback
If a failure occurs, it is typically due to one of three
main causes. The first is ineffective task allocation, where
tasks are assigned to unsuitable unmanned units, resulting in
execution failure. The second is flawed behavior tree logic,
where the node sequence or structure is unreasonable—often
a consequence of LLM hallucinations. The third stems from
operational constraints within the simulation environment
that prevent task completion. The BT execution results and
failure reasons are fed back to the LLM, allowing it to dy-
namically adjust the behavior tree for improved performance.
Additionally, human input can precisely correct and refine
the logical structure of the behavior tree. Before execution,
if errors in the behavior tree’s logic are identified by users
based on prior knowledge and experience, immediate feed-
back can be provided to prompt the LLM to adjust the
structure. Alternatively, after execution, both the execution
results and human input can be fed back to the LLM,
enabling further adjustment of the behavior tree.
IV. EXPERIMENT
A. Experiment Setting
The Microsoft AirSim [27] open-source simulator is uti-
lized to evaluate the performance of the proposed framework
for heterogeneous unmanned swarm task planning. This
platform supports both UAV and UGV simulations, offering a
comprehensive set of APIs for programmatic control of their
movement. For the simulation environment, the powerful
real-time 3D creation tools of Unreal Engine are leveraged
to construct various scenes, such as airports and subway
stations. GPT-4 is adopted as the LLM for all reasoning and
planning steps.
B. Task Setting
To comprehensively evaluate the framework proposed
in this paper, three distinct task scenarios were designed,
including an airport scenario, a subway station scenario,
and an abandoned building scenario, as shown in Fig. 1(c).
Moreover, to further assess the framework’s adaptability and
performance at different difficulty gradients, three levels of
task complexity were defined: simple tasks, complex tasks,
and heterogeneous tasks.
• Simple Tasks: Simple tasks can be executed by a
single UAV or UGV, assuming that the unmanned unit
possesses all the necessary skills and capabilities to
independently complete the task.
• Complex Tasks: Complex tasks are carried out by a
homogeneous swarm of UAVs or UGVs. These tasks
involve only one type of unmanned unit and do not
require the collaboration of heterogeneous robots.
• Heterogeneous Tasks: Heterogeneous tasks involve
both UAVs and UGVs, aiming to evaluate the coordi-
nation capabilities of mixed-type unmanned teams.
In general, 45 tasks are contained in our task dataset,
including 15 simple tasks, 15 complex tasks, and 15 het-
erogeneous tasks.
C. Evaluation Metrics
Several evaluation metrics are employed to assess the
effectiveness of our framework in unmanned swarm task
planning.
SR (Success Rate): A task is considered successful
only if the generated behavior tree is executable, logically
consistent, and capable of achieving the target task.
AS (Average Step Length): Defined as the average
number of execution steps in successful task completions,
this metric reflects the overall execution efficiency. Lower
values indicate more efficient task execution.
Exec (Executability): This metric measures whether the
generated behavior tree or Python code can be directly
executed. It reflects the ability of the LLM to produce
syntactically and structurally valid outputs that conform to
predefined formats.
TU (Token Usage): The total number of tokens consumed
by different methods, indicating their computational cost.
3584
Authorized licensed use limited to: Consortium - Saudi Arabia SDL. Downloaded on February 16,2026 at 10:06:57 UTC from IEEE Xplore.  Restrictions apply. 


--- Page 5 ---
TABLE II
EXPERIMENTAL RESULTS OF LLM-CBT AND OTHER METHODS IN DIFFERENT TYPES OF TASKS
Methods
Simple Tasks
Complex Tasks
Heterogeneous Tasks
Exe
SR
AS
TU
Exe
SR
AS
TU
Exe
SR
AS
TU
LLM-sequence
0.800
0.400
3.87
1869
0.800
0.467
5.73
1988
0.600
0.267
12.07
1973
SMART-LLM
0.867
0.800
3.93
7338
0.733
0.533
7.13
8126
0.667
0.333
11.33
8739
LLM-CBT w/o refinement
1.000
0.867
4.47
2585
0.933
0.733
5.27
2898
0.867
0.400
14.93
3058
LLM-CBT w/o feedback
1.000
0.933
4.40
4727
1.000
0.800
4.90
5141
0.933
0.667
10.20
5582
LLM-CBT(Ours)
1.000
1.000
4.40
5174
1.000
1.000
4.47
6262
1.000
0.933
9.60
6968
TABLE III
EXPERIMENTAL RESULTS OF LLM-CBT AND OTHER METHODS IN DIFFERENT TYPES OF SCENES
Methods
Airport scene
Subway Station scene
Abandoned Building scene
Exe
SR
AS
Exe
SR
AS
Exe
SR
AS
LLM-sequence
0.866
0.467
7.67
0.733
0.400
7.73
0.600
0.267
6.27
SMART-LLM
0.733
0.600
7.93
0.800
0.600
7.40
0.733
0.467
7.07
LLM-CBT w/o refinement
0.933
0.667
7.73
0.933
0.733
9.07
0.933
0.600
7.87
LLM-CBT w/o feedback
1.000
0.867
6.67
1.000
0.867
6.80
0.933
0.667
6.00
LLM-CBT(Ours)
1.000
0.933
6.47
1.000
1.000
6.13
1.000
1.000
5.87
Fig. 4.
An example of heterogeneous unmanned clusters performing tasks
in the airport scenario.
D. Experimental Results and Analysis
Based on the task settings of different scenarios and
varying complexities, the following approaches are applied to
accurately evaluate the effectiveness of the proposed method.
• LLM-sequence: Based on LLM, the few-shot approach
is adopted by this method for task decomposition and
allocation. It only consists of two stages: generation and
execution, and the subtasks are executed sequentially.
• SMART-LLM: The method comprises three stages:
task decomposition, alliance formation, and task alloca-
tion [6]. In each stage, it employs a few-shot approach
to construct programmatic LLM prompts and generates
plans in the form of Python code.
• LLM-CBT w/o refinement: This approach does not
include the refinement stage of the behavior tree in
the task planning process. The LLM Planner generates
an initial behavior tree through task decomposition and
allocation, which is then executed directly.
• LLM-CBT w/o feedback: This approach does not feed
execution feedback into the LLM for further adjust-
ments. Instead, the behavior tree generated by the LLM
Planner is refined and then executed by UAVs and
UGVs executors.
• LLM-CBT: This method is proposed in this paper and
incorporates the complete closed-loop GREF mecha-
nism.
Experimental Results: The average results across differ-
ent types of tasks for our methods and other baseline methods
are summarized in Table II. Overall, LLM-CBT delivers
favorable outcomes in terms of executability, success rate
and average step. As the task becomes more challenging, the
advantages of our method become more evident. However,
among the three metrics for simple tasks, the average step
count of our method is higher than that of LLM-sequence and
SMART-LLM. This is because the behavior tree generated
by the LLM explicitly incorporates both action preconditions
and recovery mechanisms for execution failures. As a result,
the tree contains more condition and action nodes, which
significantly improves task success rates, albeit at the cost
of increased execution steps. For complex and heteroge-
neous tasks, our method outperforms the LLM-sequence and
SMART-LLM methods across three evaluation metrics. Its
logical structure and recovery mechanisms provide better
adaptability to complex environments.
In the ablation study, LLM-CBT without refinement still
performs reasonably well on simple tasks. This phenomenon
is likely due to the nature of simple tasks, which typically
involve only a single UGV or UAV and a limited set of action
nodes. However, in the case of complex and heterogeneous
tasks, the initial behavioral tree may have problems with
logic or parameter errors due to hallucinations from the
LLM, leading to a significant decrease in the execution suc-
cess rate. The refinement module enhances the executability
of the behavioral tree and reduces the average step size
of the task execution. To evaluate the role of the feedback
component, we compare LLM-CBT with its variant without
3585
Authorized licensed use limited to: Consortium - Saudi Arabia SDL. Downloaded on February 16,2026 at 10:06:57 UTC from IEEE Xplore.  Restrictions apply. 


--- Page 6 ---
feedback. As shown in Table II, LLM-CBT outperforms
its counterpart, confirming the effectiveness of incorporating
both behavior trees and human feedback. In our complete
GREF loop, human feedback was primarily required for
heterogeneous tasks. For the experiments reported in Table
II, human feedback was involved in approximately 13% of
all task executions, and in most cases, no more than one
feedback step per task was needed. Notably, the complete
GREF loop incurs the highest token usage in the ablation
experiments, as iterative refinement and human feedback
result in longer prompts.
As shown in Table III, excellent performance is consis-
tently exhibited by our method in different scenarios. This
indicates its strong generalization to different types of scenes.
An example of successful execution of the “Unmanned clus-
ters conducting search and rescue in the area surrounding
the airport” task in an airport scenario is shown in Fig. 4.
Moreover, to evaluate the scalability of our pipeline, we also
conducted tests involving up to 20 robots, comprising 10
UAVs and 10 UGVs. Our system was able to maintain task
executability and coordination efficiency under this load.
V. CONCLUSIONS
In this paper, a novel framework for generating executable
BTs using LLM in heterogeneous unmanned swarm tasks
is proposed. Unmanned units with different action spaces
and capabilities, such as UGVs and UAVs, are effectively
leveraged by the framework to achieve efficient and precise
task coordination. Specifically, through a proposed approach
named GREF in a closed-loop task planning and execution
process, the executability of behavior trees is ensured and
the success rate of task execution is significantly improved.
The superiority of our method is demonstrated through
experiments in three different scenarios with varying task
complexities. The real-time challenges related to behavior
tree generation and dynamic adjustment during the real-
world deployment of unmanned swarms will be our future
research directions.
REFERENCES
[1] K. Kuru, “Planning the future of smart cities with swarms of fully
autonomous unmanned aerial vehicles using a novel framework,” IEEE
Access, vol. 9, pp. 6571–6595, 2021.
[2] S. HoseinDoost, T. Adamzadeh, B. Zamani, and A. Fatemi, “A model-
driven framework for developing multi-agent systems in emergency
response environments,” Software & Systems Modeling, vol. 18, no. 3,
pp. 1985–2012, 2019.
[3] A. Al-Kaff, F. M. Moreno, A. de la Escalera, and J. M. Armingol,
“Intelligent vehicle for search, rescue and transportation purposes,” in
2017 IEEE International Symposium on Safety, Security and Rescue
Robotics (SSRR).
IEEE, 2017, pp. 110–115.
[4] H. Zhang, W. Du, J. Shan, Q. Zhou, Y. Du, J. B. Tenenbaum, T. Shu,
and C. Gan, “Building cooperative embodied agents modularly with
large language models,” arXiv preprint arXiv:2307.02485, 2023.
[5] Z. Mandi, S. Jain, and S. Song, “Roco: Dialectic multi-robot col-
laboration with large language models,” in 2024 IEEE International
Conference on Robotics and Automation (ICRA).
IEEE, 2024, pp.
286–299.
[6] S. S. Kannan, V. L. Venkatesh, and B.-C. Min, “Smart-llm: Smart
multi-agent robot task planning using large language models,” in 2024
IEEE/RSJ International Conference on Intelligent Robots and Systems
(IROS).
IEEE, 2024, pp. 12 140–12 147.
[7] K. Y. Scheper, S. Tijmons, C. C. de Visser, and G. C. de Croon,
“Behavior trees for evolutionary robotics,” Artificial life, vol. 22, no. 1,
pp. 23–48, 2016.
[8] C. Deng, C. Zhao, Z. Liu, J. Zhang, Y. Wu, Y. Wang, H. Cheng, and
X. Yi, “Learning behavior trees by evolution-inspired approaches,” in
Proceedings of the Companion Conference on Genetic and Evolution-
ary Computation, 2023, pp. 275–278.
[9] E. Scheide, G. Best, and G. A. Hollinger, “Behavior tree learning for
robotic task planning through monte carlo dag search over a formal
grammar,” in 2021 IEEE International Conference on Robotics and
Automation (ICRA).
IEEE, 2021, pp. 4837–4843.
[10] P. ¨Ogren and C. I. Sprague, “Behavior trees in robot control systems,”
Annual Review of Control, Robotics, and Autonomous Systems, vol. 5,
no. 1, pp. 81–107, 2022.
[11] Z. Cai, M. Li, W. Huang, and W. Yang, “Bt expansion: a sound and
complete algorithm for behavior planning of intelligent robots with
behavior trees,” in Proceedings of the AAAI Conference on Artificial
Intelligence, vol. 35, no. 7, 2021, pp. 6058–6065.
[12] B. Banerjee, “Autonomous acquisition of behavior trees for robot
control,” in 2018 IEEE/RSJ International Conference on Intelligent
Robots and Systems (IROS).
IEEE, 2018, pp. 3460–3467.
[13] E. Giunchiglia, M. Colledanchise, L. Natale, and A. Tacchella, “Con-
ditional behavior trees: Definition, executability, and applications,” in
2019 IEEE International Conference on Systems, Man and Cybernetics
(SMC).
IEEE, 2019, pp. 1899–1906.
[14] M. Iovino, F. I. Dogan, I. Leite, and C. Smith, “Interactive disambigua-
tion for behavior tree execution. in 2022 ieee-ras 21st international
conference on humanoid robots (humanoids). 82–89,” 2022.
[15] E. Safronov, M. Colledanchise, and L. Natale, “Task planning with
belief behavior trees,” in 2020 IEEE/RSJ International Conference on
Intelligent Robots and Systems (IROS).
IEEE, 2020, pp. 6870–6877.
[16] Y. Wu, J. Li, H. Dai, X. Yi, Y. Wang, and X. Yang, “micros. bt:
An event-driven behavior tree framework for swarm robots,” in 2021
IEEE/RSJ International Conference on Intelligent Robots and Systems
(IROS).
IEEE, 2021, pp. 9146–9153.
[17] K. Liu, Z. Tang, D. Wang, Z. Wang, B. Zhao, and X. Li, “Coherent:
Collaboration of heterogeneous multi-robot system with large language
models,” arXiv preprint arXiv:2409.15146, 2024.
[18] X. Liu, P. Li, W. Yang, D. Guo, and H. Liu, “Leveraging large
language model for heterogeneous ad hoc teamwork collaboration,”
arXiv preprint arXiv:2406.12224, 2024.
[19] J. Chen, C. Yu, X. Zhou, T. Xu, Y. Mu, M. Hu, W. Shao,
Y. Wang, G. Li, and L. Shao, “Emos: Embodiment-aware heteroge-
neous multi-robot operating system with llm agents.” arXiv preprint
arXiv:2410.22662, 2024.
[20] J. Styrud, M. Iovino, M. Norrl¨of, M. Bj¨orkman, and C. Smith, “Au-
tomatic behavior tree expansion with llms for robotic manipulation,”
arXiv preprint arXiv:2409.13356, 2024.
[21] J. Ao, F. Wu, Y. Wu, A. Swikir, and S. Haddadin, “Llm as bt-planner:
Leveraging llms for behavior tree generation in robot task planning,”
arXiv preprint arXiv:2409.10444, 2024.
[22] H. Zhou, Y. Lin, L. Yan, J. Zhu, and H. Min, “Llm-bt: Performing
robotic adaptive tasks based on large language models and behavior
trees,” in 2024 IEEE International Conference on Robotics and
Automation (ICRA).
IEEE, 2024, pp. 16 655–16 661.
[23] J. Wang, A. Laurenzi, and N. Tsagarakis, “Autonomous behavior
planning for humanoid loco-manipulation through grounded language
model,” in 2024 IEEE/RSJ International Conference on Intelligent
Robots and Systems (IROS).
IEEE, 2024, pp. 10 856–10 863.
[24] J. Xiong, J. Li, J. Li, S. Kang, C. Liu, and C. Yang, “Probability-
tuned market-based allocations for uav swarms under unreliable ob-
servations,” IEEE Transactions on Cybernetics, vol. 53, no. 11, pp.
6803–6814, 2022.
[25] G. Ma, H. Duan, and S. Liu, “Improved ant colony algorithm for
global optimal trajectory planning of uav under complex environment.”
International Journal of Computer Science & Application, vol. 4,
no. 3, pp. 57–68, 2007.
[26] Z. Zhang, J. Jiang, X. Haiyan, and W.-A. Zhang, “Distributed dy-
namic task allocation for unmanned aerial vehicle swarm systems: A
networked evolutionary game-theoretic approach,” Chinese Journal of
Aeronautics, vol. 37, no. 6, pp. 182–204, 2024.
[27] S. Shah, D. Dey, C. Lovett, and A. Kapoor, “Airsim: High-fidelity
visual and physical simulation for autonomous vehicles,” in Field
and Service Robotics: Results of the 11th International Conference.
Springer, 2018, pp. 621–635.
3586
Authorized licensed use limited to: Consortium - Saudi Arabia SDL. Downloaded on February 16,2026 at 10:06:57 UTC from IEEE Xplore.  Restrictions apply. 
